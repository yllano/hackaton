{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3e8f6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e82e4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruta de entrada: 01_data\\input\\Online Retail.csv\n",
      "Dataset cargado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. CONFIGURACIÓN DE RUTAS Y CARGA ---\n",
    "# Usamos 'os.path.join' para crear rutas que funcionen en cualquier sistema operativo.\n",
    "INPUT_PATH = os.path.join('01_data', 'input', 'Online Retail.csv')\n",
    "OUTPUT_PATH = os.path.join('01_data', 'output', 'master_df.csv')\n",
    "\n",
    "print(\"Ruta de entrada:\", INPUT_PATH)\n",
    "\n",
    "try:\n",
    "    # Carga del dataset con el encoding correcto\n",
    "    initial_len = len(df)\n",
    "    df = pd.read_csv(INPUT_PATH, encoding='ISO-8859-1')\n",
    "    print(\"Dataset cargado exitosamente.\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: No se pudo cargar el archivo. Verifica la ruta y el nombre (debe ser Online Retail.csv). Detalle: {e}\")\n",
    "    # Si hay error, detenemos la ejecución aquí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3071dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros después de la limpieza avanzada: 344941\n",
      "Total de registros eliminados: 0\n"
     ]
    }
   ],
   "source": [
    "# 1. Manejo de Nulos: Eliminar registros sin ID de Cliente o Descripción.\n",
    "df.dropna(subset=['CustomerID', 'Description'], inplace=True)\n",
    "\n",
    "# 2. Conversión de Tipos de Datos (antes de la limpieza numérica)\n",
    "df['CustomerID'] = df['CustomerID'].astype(int)\n",
    "df['UnitPrice'] = df['UnitPrice'].astype(float)\n",
    "df['Quantity'] = df['Quantity'].astype(int)\n",
    "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "\n",
    "# 3. Eliminar Duplicados (Esencial para transacciones)\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "\n",
    "# --- 3. LIMPIEZA AVANZADA (Valores Atípicos y Errores) ---\n",
    "\n",
    "# 4. Eliminar Precios y Cantidades Negativas o Cero (CRUCIAL para Elasticidad)\n",
    "# Estas filas representan devoluciones, errores o productos gratuitos.\n",
    "df = df[df['Quantity'] > 0]\n",
    "df = df[df['UnitPrice'] > 0]\n",
    "\n",
    "# 5. Eliminar Outliers Extremos de Precio\n",
    "# Usamos el percentil 99.5% para eliminar precios inusualmente altos que distorsionan el modelo.\n",
    "price_threshold = df['UnitPrice'].quantile(0.995)\n",
    "df = df[df['UnitPrice'] < price_threshold]\n",
    "\n",
    "# 6. Eliminar Outliers Extremos de Cantidad\n",
    "# Usamos el percentil 99.5% para eliminar compras de inventario a granel o errores de ingreso.\n",
    "quantity_threshold = df['Quantity'].quantile(0.995)\n",
    "df = df[df['Quantity'] < quantity_threshold]\n",
    "\n",
    "# 7. Limpieza por Tasa de Cancelación (Para identificar SKUs problemáticos)\n",
    "# Eliminar códigos de stock que no son productos reales (ej. Códigos de ajuste 'POST', 'D', 'DOT')\n",
    "non_product_codes = ['POST', 'D', 'DOT', 'M', 'S', 'AMAZONFEE', 'CRUK']\n",
    "df = df[~df['StockCode'].isin(non_product_codes)]\n",
    "\n",
    "# 8. Filtrar por Duración del Dataset\n",
    "# Nos enfocamos en el grueso del año de ventas, eliminando datos incompletos del inicio/final.\n",
    "df = df[df['InvoiceDate'].dt.year == 2011]\n",
    "# Filtraremos solo por las fechas más robustas (ej. Enero a Noviembre)\n",
    "df = df[df['InvoiceDate'] < '2011-12-01'] \n",
    "\n",
    "print(f\"Registros después de la limpieza avanzada: {len(df)}\")\n",
    "print(f\"Total de registros eliminados: {initial_len - len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4dcb09b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ajuste de moneda simulado completado.\n"
     ]
    }
   ],
   "source": [
    "# --- 3. FEATURE ENGINEERING Y RE-CONTEXTUALIZACIÓN GEOGRÁFICA Y DE MONEDA ---\n",
    "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "df['Month'] = df['InvoiceDate'].dt.month\n",
    "df['DayOfWeek'] = df['InvoiceDate'].dt.dayofweek # Lunes=0, Domingo=6\n",
    "\n",
    "# Mapeo estratégico de países y Tasas de Conversión Simuladas\n",
    "# Tasas simuladas: Multiplicador del precio original (GBP) para simular la moneda local.\n",
    "conversion_rates = {\n",
    "    'United Kingdom': {'new_country': 'MEXICO', 'rate': 25.0, 'currency': 'MXN'}, \n",
    "    'Germany': {'new_country': 'COLOMBIA', 'rate': 4500.0, 'currency': 'COP'},\n",
    "    'France': {'new_country': 'CHILE', 'rate': 1000.0, 'currency': 'CLP'},\n",
    "    'EIRE': {'new_country': 'PERU', 'rate': 4.0, 'currency': 'PEN'},\n",
    "    'Spain': {'new_country': 'ARGENTINA', 'rate': 900.0, 'currency': 'ARS'},\n",
    "    'Netherlands': {'new_country': 'BRASIL', 'rate': 6.0, 'currency': 'BRL'},\n",
    "}\n",
    "\n",
    "# Crear las nuevas columnas de País y Moneda\n",
    "df['Original_Country'] = df['Country']\n",
    "df['Country'] = df['Original_Country'].apply(\n",
    "    lambda x: conversion_rates.get(x, {}).get('new_country', 'Otro_LATAM')\n",
    ")\n",
    "# ************** COLUMNA SOLICITADA **************\n",
    "df['Local_Currency'] = df['Original_Country'].apply(\n",
    "    lambda x: conversion_rates.get(x, {}).get('currency', 'USD')\n",
    ")\n",
    "# ************************************************\n",
    "\n",
    "# Aplicar la conversión del precio a la moneda local simulada\n",
    "def convert_price(row):\n",
    "    original_country = row['Original_Country']\n",
    "    rate = conversion_rates.get(original_country, {}).get('rate', 1.0)\n",
    "    return row['UnitPrice'] * rate\n",
    "\n",
    "df['UnitPrice_Local'] = df.apply(convert_price, axis=1)\n",
    "\n",
    "print(\"Ajuste de moneda simulado completado.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ccd1007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ DataFrame Maestro regenerado con CustomerID a nivel de transacción.\n"
     ]
    }
   ],
   "source": [
    "# --- 5. AGREGACIÓN DE DEMANDA Y SIMULACIÓN DE COMPETENCIA (CORREGIDA) ---\n",
    "\n",
    "# A. Crear subconjunto de productos TOP\n",
    "top_items = df.groupby('StockCode')['Quantity'].sum().nlargest(50).index\n",
    "df_filtered = df[df['StockCode'].isin(top_items)]\n",
    "\n",
    "# B. Agregación: Crearemos un master donde cada fila es una transición de cliente/producto/día.\n",
    "# Esto asegura que el CustomerID se mantenga para el RFM.\n",
    "# Usamos InvoiceNo en el groupby para mantener la unicidad de las transacciones (es un buen proxy).\n",
    "df_master = df_filtered.groupby(\n",
    "    ['InvoiceNo', 'StockCode', 'Country', 'Local_Currency', 'CustomerID', 'InvoiceDate', 'UnitPrice_Local']\n",
    ").agg(\n",
    "    # La cantidad total vendida en esa transacción específica\n",
    "    Total_Quantity_Sold=('Quantity', 'sum')\n",
    ").reset_index().rename(columns={'UnitPrice_Local': 'UnitPrice'})\n",
    "\n",
    "# C. Crear Features de Tiempo (Se perdieron en la agregación, las re-creamos)\n",
    "df_master['InvoiceDate'] = pd.to_datetime(df_master['InvoiceDate'])\n",
    "df_master['Month'] = df_master['InvoiceDate'].dt.month\n",
    "df_master['DayOfWeek'] = df_master['InvoiceDate'].dt.dayofweek\n",
    "\n",
    "# D. Simulación del Precio de la Competencia (Competitor_Price)\n",
    "df_master['Competitor_Price'] = np.random.normal(\n",
    "    loc=df_master['UnitPrice'],\n",
    "    scale=df_master['UnitPrice'] * 0.05\n",
    ")\n",
    "df_master['Competitor_Price'] = df_master['Competitor_Price'].apply(lambda x: max(x, 0.01))\n",
    "\n",
    "print(\"\\n✅ DataFrame Maestro regenerado con CustomerID a nivel de transacción.\")\n",
    "\n",
    "# --- 6. GUARDAR EL RESULTADO ---\n",
    "# ASEGÚRATE DE GUARDAR EL ARCHIVO master_df.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ef8364b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ FASE 1 COMPLETADA. Archivo master_df.csv guardado en: 01_data\\output\\master_df.csv\n"
     ]
    }
   ],
   "source": [
    "# --- 5. GUARDAR EL RESULTADO ---\n",
    "os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n",
    "df_master.to_csv(OUTPUT_PATH, index=False)\n",
    "print(f\"\\n✅ FASE 1 COMPLETADA. Archivo master_df.csv guardado en: {OUTPUT_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
